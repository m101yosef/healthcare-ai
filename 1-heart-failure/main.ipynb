{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e406b0f",
   "metadata": {},
   "source": [
    "**Can we predict heart failure from basic features?**\n",
    "\n",
    "In this episode, we will try together to find out how much we can go with this simple data and simple features that we have. What is the accuracy level that we can get? How many models should we build? \n",
    "\n",
    "<br>\n",
    "\n",
    "**About the Healthcare AI Series**\n",
    "\n",
    "This will be a new series where I will choose a healthcare problem or topic and analyse it. This is not just another machine learning experiment. This is about people. It’s about using numbers to understand risk, reveal patterns, and hopefully, make a difference.\n",
    "\n",
    "**Why?** I want to specialise in healthcare AI, and I believe the best way to learn is to work on real problems, not just tutorials. I also want to build a public body of work that reflects both skill and purpose — something that helps others while helping me grow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fe18f8",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a8a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# libraries for modelling \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "# load the data\n",
    "URL = '/kaggle/input/heart-failure-prediction/heart.csv'\n",
    "data = pd.read_csv(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa3784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify columns based on dataset documentation\n",
    "cat_cols = ['Sex', 'FastingBS', 'ExerciseAngina', 'ChestPainType', \n",
    "            'RestingECG', 'ST_Slope']\n",
    "num_cols = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']\n",
    "target_col = 'HeartDisease'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6665f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(features, kind, \n",
    "                 data=data,\n",
    "                 title='Features vs Target', \n",
    "                 target=target_col):\n",
    "    \"\"\"\n",
    "    Plots multiple features against the target variable using different plot types.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : list of str\n",
    "        List of feature column names to plot.\n",
    "    kind : str\n",
    "        Type of plot to use. Options: 'count' (categorical countplot), \n",
    "        'box' (boxplot for numerical features), 'violin' (violin plot for numerical features), \n",
    "        'kde' (kernel density estimate for numerical features).\n",
    "    data : pandas.DataFrame, optional\n",
    "        DataFrame containing the data. Defaults to the global 'data'.\n",
    "    title : str, optional\n",
    "        Title for the entire figure. Defaults to 'Features vs Target'.\n",
    "    target : str, optional\n",
    "        Name of the target column. Defaults to the global 'target_col'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Displays the plots.\n",
    "    \"\"\"\n",
    "    n_features = len(features)\n",
    "    n_cols = 3\n",
    "    n_rows = int(np.ceil(n_features / n_cols))\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "    for i, feature in enumerate(features):\n",
    "        if kind == 'count':\n",
    "            sns.countplot(data=data, x=feature, hue=target, palette=['teal', 'crimson'], ax=axes[i])\n",
    "        elif kind == 'box':\n",
    "            sns.boxplot(data=data, hue=target, y=feature, palette=['teal', 'crimson'], ax=axes[i])\n",
    "        elif kind == 'violin':\n",
    "            sns.violinplot(data=data, x=feature, hue=target, split=True, palette=['teal', 'crimson'], ax=axes[i])\n",
    "        elif kind == 'kde':\n",
    "            for label, color in zip([0, 1], ['teal', 'crimson']):\n",
    "                subset = data[data[target] == label]\n",
    "                sns.kdeplot(subset[feature], ax=axes[i], label=f'{target}={label}', color=color)\n",
    "        axes[i].set_xlabel('')\n",
    "        axes[i].set_ylabel('')\n",
    "        axes[i].set_title(feature, fontsize=16)\n",
    "        if axes[i].get_legend() is not None:\n",
    "            axes[i].get_legend().remove()\n",
    "    # Hide unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "    fig.suptitle(f\"{title}\\n\", fontsize=22, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ce519e",
   "metadata": {},
   "source": [
    "# 1. Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6f4eaa",
   "metadata": {},
   "source": [
    "Our dataset has 918 patient records with 12 features. The target variable, `HeartDisease`, indicates the presence (1) or absence (0) of heart disease. For the initial analysis, I will start with the dataset's size, structure, and key attributes, then I'll look at whether 'HeartDisease' cases are balanced or not. After that, I will explore how features related to 'HeartDisease' and&mdash;how they correlate with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df97c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values in the data\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f574d92",
   "metadata": {},
   "source": [
    "## Target Class Balance\n",
    "The dataset is nearly balanced, with 44.7% of patients not having heart disease and 55.3% having heart disease. There are no missing values, which simplifies the data preparation process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d78e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising class balance\n",
    "class_balance = data['HeartDisease'].value_counts().sort_index(ascending=True)\n",
    "wedges, texts, autotexts = plt.pie(\n",
    "    class_balance,\n",
    "    labels=['No Disease (0)', 'Has Disease (1)'],\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=90,\n",
    "    colors=['teal', 'crimson'],\n",
    "    wedgeprops={'width': 0.65}\n",
    ")\n",
    "\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontsize(12)\n",
    "    autotext.set_fontweight('bold')\n",
    "\n",
    "plt.setp(texts, size=12, weight='bold', color='black')\n",
    "plt.text(0, 0, 'Class\\nBalance', ha='center', va='center', fontsize=12)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b4e1f4",
   "metadata": {},
   "source": [
    "## Categorical features vs. target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4b7211",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(features=cat_cols, title='Categorical Features vs Target', kind='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fddf7a2",
   "metadata": {},
   "source": [
    "## Numerical features vs. target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad9c626",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(features=num_cols, title='Numerical Features vs Target', kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a62e871",
   "metadata": {},
   "source": [
    "## Features vs. target summary\n",
    "\n",
    "\n",
    "<div style=\"margin-top: 1em; border-radius: 8px; overflow: hidden; box-shadow: 0 4px 12px rgba(0,0,0,0.08);\">\n",
    "<table style=\"border-collapse: collapse; width: 100%; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; font-size: 15px; background: white;\">\n",
    "    <thead>\n",
    "    <tr style=\"background: linear-gradient(135deg, crimson, #2c3e50); color: white;\">\n",
    "        <th style=\"padding: 14px 16px; text-align: left; font-weight: 600;\">Feature</th>\n",
    "        <th style=\"padding: 14px 16px; text-align: left; font-weight: 600;\">Risk Indicator</th>\n",
    "        <th style=\"padding: 14px 16px; text-align: left; font-weight: 600;\">Notes</th>\n",
    "    </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "    <tr><th>Categorical Features</th></tr>\n",
    "    <tr style=\"transition: background-color 0.2s;\">\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; font-weight: 600;\">Sex = M</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; color: #e74c3c; font-weight: 500;\">Higher risk</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1;\">Males are more prone to heart issues, especially at younger ages</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #f8f9fa; transition: background-color 0.2s;\">\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; font-weight: 600;\">FastingBS = 1</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; color: #e74c3c; font-weight: 500;\">Higher risk</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1;\">High fasting blood sugar (likely diabetic) increases heart risk</td>\n",
    "    </tr>\n",
    "    <tr style=\"transition: background-color 0.2s;\">\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; font-weight: 600;\">ExerciseAngina = Y</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; color: #e74c3c; font-weight: 500;\">Higher risk</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1;\">Indicates chest pain during exertion — often a sign of blocked arteries</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #f8f9fa; transition: background-color 0.2s;\">\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; font-weight: 600;\">ChestPainType = ASY</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; color: #e74c3c; font-weight: 500;\">Higher risk</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1;\">Asymptomatic patients can still have serious heart conditions</td>\n",
    "    </tr>\n",
    "    <tr style=\"transition: background-color 0.2s;\">\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; font-weight: 600;\">ST_Slope = Flat</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; color: #e74c3c; font-weight: 500;\">Higher risk</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1;\">Associated with ST depression and reduced blood flow during exercise</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #f8f9fa; transition: background-color 0.2s;\">\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; font-weight: 600;\">RestingECG = LVH</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; color: #f39c12; font-weight: 500;\">Moderate risk</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1;\">Suggests left ventricular hypertrophy — a possible indicator of strain</td>\n",
    "    </tr>\n",
    "    <tr><th>Numerical Features</th></tr>\n",
    "    <tr style=\"transition: background-color 0.2s;\">\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; font-weight: 600;\">Age</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; font-weight: 500; color: #e74c3c;\">↑ Higher age → ↑ risk</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1;\">Cardiovascular vulnerability increases with age</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #f8f9fa; transition: background-color 0.2s;\">\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; font-weight: 600;\">RestingBP</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; font-weight: 500;\">Slightly elevated in heart disease</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1;\">Limited standalone predictive value due to significant group overlap</td>\n",
    "    </tr>\n",
    "    <tr style=\"transition: background-color 0.2s;\">\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; font-weight: 600;\">Cholesterol</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; font-weight: 500; color: #7f8c8d;\">No clear pattern (inconclusive)</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1;\">Impact may be better assessed through feature combinations</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #f8f9fa; transition: background-color 0.2s;\">\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; font-weight: 600;\">MaxHR</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; font-weight: 500; color: #e74c3c;\">↓ Lower in heart disease</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1;\">Reduced peak heart rate indicates impaired cardiac response to stress</td>\n",
    "    </tr>\n",
    "    <tr style=\"transition: background-color 0.2s;\">\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; font-weight: 600;\">Oldpeak</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1; font-weight: 500; color: #e74c3c;\">↑ Higher in heart disease</td>\n",
    "        <td style=\"padding: 12px 16px; border-bottom: 1px solid #ecf0f1;\">Indicates ST depression, suggesting myocardial ischemia during exercise</td>\n",
    "    </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0934c9",
   "metadata": {},
   "source": [
    "## Numerical features distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e557ef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(features=num_cols, title='Numerical Features Distribution', kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9925dee3",
   "metadata": {},
   "source": [
    "For Cholesterol and Oldpeak, there is a different distribution of values, indicating potential differences in heart stress responses and maybe I need to split these two features into more than one group of values (I will test this assumption later)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffed6e50",
   "metadata": {},
   "source": [
    "## Features correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1889dad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "corr = data.corr(numeric_only=True)\n",
    "sns.heatmap(corr, annot=True, cmap='Greens')\n",
    "plt.title('Feature Correlation Heatmap\\n', fontsize=20, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4acb12",
   "metadata": {},
   "source": [
    "MaxHR and Oldpeak show moderate negative and positive correlations with heart disease, respectively, suggesting these features are important predictors. However, the wide spread in cholesterol levels and the slight increase in resting blood pressure in the disease group indicate that these features may have a less direct impact on heart disease risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c312c9aa",
   "metadata": {},
   "source": [
    "# 2. Add Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fec38c",
   "metadata": {},
   "source": [
    "Based on the results from exploring the numerical features distribution, we can create two features: \n",
    "- **Cholesterol groups** (levels: >80 ?)\n",
    "- **Oldpeak groups** (levels: >0.7 ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88673c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot Cholesterol distribution\n",
    "sns.kdeplot(data=data, x='Cholesterol', ax=ax1, color='teal')\n",
    "ax1.axvline(x=80, color='crimson', linestyle='--')\n",
    "ax1.set_title('Distribution of Cholesterol')\n",
    "ax1.set_xlabel('Cholesterol')\n",
    "\n",
    "# Plot Oldpeak distribution\n",
    "sns.kdeplot(data=data, x='Oldpeak', ax=ax2, color='teal')\n",
    "ax2.axvline(x=0.7, color='crimson', linestyle='--')\n",
    "ax2.set_title('Distribution of Oldpeak')\n",
    "ax2.set_xlabel('Oldpeak')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea25134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification of Cholesterol levels\n",
    "data['LawChol'] = data['Cholesterol'] > 100\n",
    "data['LawChol'] = data['LawChol'].astype(int)\n",
    "data.groupby('HeartDisease')['LawChol'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6b81b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='LawChol', data=data, hue='HeartDisease', palette=['teal', 'crimson'])\n",
    "plt.title('Cholesterol levels vs. Heart Disease')\n",
    "plt.xlabel('Cholesterol levels (0: <=150, 1: >150)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa97c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification of Oldpeak levels\n",
    "data['LawOldpeak'] = data['Oldpeak'] < 0.7\n",
    "data['LawOldpeak'] = data['LawOldpeak'].astype(int)\n",
    "data['LawOldpeak'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c250bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Oldpeak levels against Heart Disease\n",
    "sns.countplot(x='LawOldpeak', data=data, hue='HeartDisease', palette=['teal', 'crimson'])\n",
    "plt.title('Oldpeak levels vs. Heart Disease')\n",
    "plt.xlabel('Oldpeak levels (0: >=0.7, 1: <0.7)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b9cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update columns classification\n",
    "cat_cols = ['Sex', 'FastingBS', 'ExerciseAngina', 'ChestPainType', \n",
    "            'RestingECG', 'ST_Slope', 'LawChol', 'LawOldpeak']\n",
    "num_cols = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']\n",
    "target_col = 'HeartDisease'\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bbaa31",
   "metadata": {},
   "source": [
    "# 3. Baseline Model - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca47f99",
   "metadata": {},
   "source": [
    "For a baseline model, I would start with a Random Forest classifier. It is generally robust, performs well across a variety of datasets, and is less prone to overfitting compared to single decision trees. It also provides a good balance between performance and complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2f91e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "y = data[target_col]\n",
    "X = data.drop(columns=[target_col])\n",
    "\n",
    "# Split data: 70% train, 15% val, 15% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Splitted \\nTrain shape: {X_train.shape}, Val shape: {X_val.shape}, Test shape: {X_test.shape}\")\n",
    "\n",
    "# Calculate percentages\n",
    "total_samples = len(X_train) + len(X_val) + len(X_test)\n",
    "train_pct = len(X_train) / total_samples * 100\n",
    "val_pct = len(X_val) / total_samples * 100\n",
    "test_pct = len(X_test) / total_samples * 100\n",
    "\n",
    "# Create pie chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie([train_pct, val_pct, test_pct], \n",
    "    labels=['Train', 'Validation', 'Test'],\n",
    "    autopct='%1.1f%%',\n",
    "    colors=['whitesmoke', 'lightblue', 'lightcoral'])\n",
    "plt.title('Data Split Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dd9555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features for Random Forest\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoder.fit(X_train[cat_cols])\n",
    "\n",
    "def encode_and_concat(X):\n",
    "    cat_encoded = encoder.transform(X[cat_cols])\n",
    "    cat_encoded_df = pd.DataFrame(cat_encoded, columns=encoder.get_feature_names_out(cat_cols), index=X.index)\n",
    "    return pd.concat([X[num_cols].reset_index(drop=True), cat_encoded_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "X_train_rf = encode_and_concat(X_train)\n",
    "X_val_rf = encode_and_concat(X_val)\n",
    "X_test_rf = encode_and_concat(X_test)\n",
    "\n",
    "X_train_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae6bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with Grid Search and Stratified K-Fold CV (using encoded data)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "gs = GridSearchCV(rf, param_grid, cv=skf, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "gs.fit(X_train_rf, y_train)\n",
    "\n",
    "print(f\"Best parameters: {gs.best_params_}\")\n",
    "print(f\"Best CV accuracy: {gs.best_score_:.4f}\")\n",
    "\n",
    "val_preds = gs.predict(X_val_rf)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, val_preds))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, val_preds))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, val_preds))\n",
    "\n",
    "# Visualize confusion matrix as a heatmap\n",
    "cm = confusion_matrix(y_val, val_preds)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Validation Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5823db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on the test set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "test_preds = gs.predict(X_test_rf)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, test_preds))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, test_preds))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, test_preds))\n",
    "\n",
    "# Visualize confusion matrix as a heatmap\n",
    "cm = confusion_matrix(y_test, test_preds)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Test Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c22c7b8",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "- The model achieves a high test accuracy (~89%), indicating strong generalization to unseen data.\n",
    "- Both classes are predicted with high precision and recall, with slightly better recall for the positive class (1).\n",
    "- The confusion matrix shows a low number of false positives and false negatives.\n",
    "- The model's performance on the test set is even better than on the validation set, suggesting robust training and no overfitting.\n",
    "\n",
    "**Final Suggestions**\n",
    "- Consider analysing feature importances to gain insights into which variables are most influential.\n",
    "- If even higher performance is needed, try more advanced models or ensemble techniques.\n",
    "- Continue monitoring for data drift or changes if deploying in a real-world setting.\n",
    "- Document and communicate these results to stakeholders for further decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aa2be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze and plot feature importances\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get feature importances from the best estimator\n",
    "top_rf = gs.best_estimator_\n",
    "importances = top_rf.feature_importances_\n",
    "feature_names = list(X_train_rf.columns)\n",
    "\n",
    "# Sort features by importance\n",
    "dx = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Top 15 Feature Importances (Random Forest)')\n",
    "plt.bar(range(15), importances[dx][:15], align='center', color='crimson')\n",
    "plt.xticks(range(15), [feature_names[i] for i in dx[:15]], rotation=45, ha='right')\n",
    "plt.ylabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print all features\n",
    "for i in range(25):\n",
    "    print(f\"{i+1}. {feature_names[dx[i]]}: {importances[dx[i]]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c295d1",
   "metadata": {},
   "source": [
    "- **Most influential features:**  \n",
    "  - `ST_Slope_Up` (0.1969) and `ST_Slope_Flat` (0.1117) are by far the most important, highlighting the predictive power of ST segment slope during exercise.\n",
    "  - `ExerciseAngina_N` (0.0846) and `ExerciseAngina_Y` (0.0701) together indicate that the presence or absence of exercise-induced angina is a strong predictor.\n",
    "  - `ChestPainType_ASY` (0.0766) and `Oldpeak` (0.0759) are also highly influential, aligning with clinical expectations.\n",
    "\n",
    "- **Moderately important features:**  \n",
    "  - `Cholesterol` (0.0617), `MaxHR` (0.0535), and `Age` (0.0379) contribute meaningfully, reflecting known cardiovascular risk factors.\n",
    "  - Engineered features like `LawOldpeak_1` (0.0339), `RestingBP` (0.0326), `LawOldpeak_0` (0.0210), and `LawChol_0` (0.0207) also show moderate importance.\n",
    "  - `ChestPainType_ATA` (0.0169), `Sex_F` (0.0166), `LawChol_1` (0.0155), `ChestPainType_NAP` (0.0154), and `Sex_M` (0.0152) have smaller but non-negligible contributions.\n",
    "\n",
    "- **Least important features:**  \n",
    "  - Features such as `FastingBS_1` (0.0107), `FastingBS_0` (0.0099), `RestingECG_Normal` (0.0066), `RestingECG_LVH` (0.0063), `ST_Slope_Down` (0.0046), `RestingECG_ST` (0.0028), and `ChestPainType_TA` (0.0025) have relatively low importance (<0.012).\n",
    "  - These features contribute less to the model’s predictions, but their removal should only be considered if it does not reduce model performance.\n",
    "\n",
    "**Summary & Suggestions**\n",
    "\n",
    "- The model relies most on exercise-related ECG features and symptoms, which is consistent with medical knowledge.\n",
    "- Demographic features (like sex) and fasting blood sugar have low importance in this dataset/model.\n",
    "- Consider focusing on the most influential features for further analysis or model simplification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b228a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Random Forest model performance and feature importances to CSV\n",
    "perf_rows = []\n",
    "for split, X_, y_, preds in [\n",
    "    ('validation', X_val_rf, y_val, val_preds),\n",
    "    ('test', X_test_rf, y_test, test_preds),\n",
    "    ]:\n",
    "    perf_rows.append({\n",
    "        'model': 'RandomForest',\n",
    "        'split': split,\n",
    "        'accuracy': accuracy_score(y_, preds),\n",
    "        'precision': precision_score(y_, preds),\n",
    "        'recall': recall_score(y_, preds),\n",
    "        'f1': f1_score(y_, preds)\n",
    "    })\n",
    "perf_df = pd.DataFrame(perf_rows)\n",
    "perf_df.to_csv('../data/model_performance.csv', mode='a', header=False, index=False)\n",
    "\n",
    "# Save top 25 feature importances\n",
    "fi_df = pd.DataFrame({\n",
    "    'model': 'RandomForest',\n",
    "    'feature': [feature_names[i] for i in dx[:25]],\n",
    "    'importance': importances[dx[:25]]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2980479",
   "metadata": {},
   "source": [
    "# 4. Models Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a59334",
   "metadata": {},
   "source": [
    "I've repeated step 3 and built three other models: \n",
    "- XGBoost\n",
    "- Logistic Regression \n",
    "- Multi-layer Perceptron (MLP)\n",
    "\n",
    "I used grid search and cross-validation to find the best settings for each model. After that, I checked how well each model did on the validation and test sets, using accuracy, precision, recall, and F1-score.\n",
    "\n",
    "<br>\n",
    "\n",
    "If you want to see the code, visit [this repo](https://github.com/m101yosef/healthcare-ai/tree/main/1-heart-failure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8602ee83",
   "metadata": {},
   "source": [
    "![Models Performance](https://github.com/m101yosef/healthcare-ai/raw/main/1-heart-failure/image/models-performance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a200b1",
   "metadata": {},
   "source": [
    "**Key Observations**\n",
    "- All models performed similarly, with high accuracy (around 89%). \n",
    "- The most important features were things like ST segment slope, exercise-induced angina, chest pain type, and oldpeak.\n",
    "- The models agree on what’s important, which matches what doctors expect.\n",
    "- No single model was a clear winner, but all gave useful insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef023616",
   "metadata": {},
   "source": [
    "![Features importance](https://github.com/m101yosef/healthcare-ai/raw/main/1-heart-failure/image/features-importance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6965f94e",
   "metadata": {},
   "source": [
    "Differences in feature importance rankings highlight how each model leverages different aspects of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb12091",
   "metadata": {},
   "source": [
    "# Reflection\n",
    "**What I Did Right**\n",
    "- I used a fair data split and cross-validation to avoid overfitting.\n",
    "- I tried several types of models, from simple to more complex.\n",
    "- I checked feature importance to understand what drives predictions.\n",
    "- I kept the process transparent and reproducible.\n",
    "\n",
    "<br>\n",
    "\n",
    "**What I Did Wrong / Could Improve**\n",
    "\n",
    "- I could have tried more advanced models or combined models (ensembles) for even better results.\n",
    "- I didn’t do much feature engineering—creating new features or combining existing ones might help.\n",
    "- I could have looked for more data or tried to balance the classes if they were uneven.\n",
    "- I didn’t use external validation (like data from another hospital) to check if the models generalize.\n",
    "- I could have spent more time on data cleaning and outlier detection.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Next Steps**\n",
    "\n",
    "- Try ensemble methods: Combine several models for better accuracy.\n",
    "- Add more data: More data usually means better models.\n",
    "- Read research papers: See what the latest science says about heart disease prediction.\n",
    "- Work with doctors: Get expert feedback to make the models more useful in real life.\n",
    "- Deploy the model: Build a simple app or dashboard for doctors or patients.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "Thank you for reading! <br>\n",
    "*See you in the next episode*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
